[{"text": "Power.", "start": 15.26, "duration": 2.0}, {"text": "That is the word that comes to mind.", "start": 17.26, "duration": 2.0}, {"text": "We're the new technologists.", "start": 19.26, "duration": 2.0}, {"text": "We have a lot of data, so we have a lot of power.", "start": 21.26, "duration": 3.0}, {"text": "How much power do we have?", "start": 24.26, "duration": 2.0}, {"text": "Scene from a movie: \"Apocalypse Now\" -- great movie.", "start": 26.26, "duration": 3.0}, {"text": "We've got to get our hero, Captain Willard, to the mouth of the Nung River", "start": 29.26, "duration": 3.0}, {"text": "so he can go pursue Colonel Kurtz.", "start": 32.26, "duration": 2.0}, {"text": "The way we're going to do this is fly him in and drop him off.", "start": 34.26, "duration": 2.0}, {"text": "So the scene:", "start": 36.26, "duration": 2.0}, {"text": "the sky is filled with this fleet of helicopters carrying him in.", "start": 38.26, "duration": 3.0}, {"text": "And there's this loud, thrilling music in the background,", "start": 41.26, "duration": 2.0}, {"text": "this wild music.", "start": 43.26, "duration": 2.0}, {"text": "\u266b Dum da ta da dum \u266b", "start": 45.26, "duration": 2.0}, {"text": "\u266b Dum da ta da dum \u266b", "start": 47.26, "duration": 2.0}, {"text": "\u266b Da ta da da \u266b", "start": 49.26, "duration": 3.0}, {"text": "That's a lot of power.", "start": 52.26, "duration": 2.0}, {"text": "That's the kind of power I feel in this room.", "start": 54.26, "duration": 2.0}, {"text": "That's the kind of power we have", "start": 56.26, "duration": 2.0}, {"text": "because of all of the data that we have.", "start": 58.26, "duration": 2.0}, {"text": "Let's take an example.", "start": 60.26, "duration": 2.0}, {"text": "What can we do", "start": 62.26, "duration": 2.0}, {"text": "with just one person's data?", "start": 64.26, "duration": 3.0}, {"text": "What can we do", "start": 67.26, "duration": 2.0}, {"text": "with that guy's data?", "start": 69.26, "duration": 2.0}, {"text": "I can look at your financial records.", "start": 71.26, "duration": 2.0}, {"text": "I can tell if you pay your bills on time.", "start": 73.26, "duration": 2.0}, {"text": "I know if you're good to give a loan to.", "start": 75.26, "duration": 2.0}, {"text": "I can look at your medical records; I can see if your pump is still pumping --", "start": 77.26, "duration": 3.0}, {"text": "see if you're good to offer insurance to.", "start": 80.26, "duration": 3.0}, {"text": "I can look at your clicking patterns.", "start": 83.26, "duration": 2.0}, {"text": "When you come to my website, I actually know what you're going to do already", "start": 85.26, "duration": 3.0}, {"text": "because I've seen you visit millions of websites before.", "start": 88.26, "duration": 2.0}, {"text": "And I'm sorry to tell you,", "start": 90.26, "duration": 2.0}, {"text": "you're like a poker player, you have a tell.", "start": 92.26, "duration": 2.0}, {"text": "I can tell with data analysis what you're going to do", "start": 94.26, "duration": 2.0}, {"text": "before you even do it.", "start": 96.26, "duration": 2.0}, {"text": "I know what you like. I know who you are,", "start": 98.26, "duration": 3.0}, {"text": "and that's even before I look at your mail", "start": 101.26, "duration": 2.0}, {"text": "or your phone.", "start": 103.26, "duration": 2.0}, {"text": "Those are the kinds of things we can do", "start": 105.26, "duration": 2.0}, {"text": "with the data that we have.", "start": 107.26, "duration": 3.0}, {"text": "But I'm not actually here to talk about what we can do.", "start": 110.26, "duration": 3.0}, {"text": "I'm here to talk about what we should do.", "start": 116.26, "duration": 3.0}, {"text": "What's the right thing to do?", "start": 120.26, "duration": 3.0}, {"text": "Now I see some puzzled looks", "start": 124.26, "duration": 2.0}, {"text": "like, \"Why are you asking us what's the right thing to do?", "start": 126.26, "duration": 3.0}, {"text": "We're just building this stuff. Somebody else is using it.\"", "start": 129.26, "duration": 3.0}, {"text": "Fair enough.", "start": 132.26, "duration": 3.0}, {"text": "But it brings me back.", "start": 135.26, "duration": 2.0}, {"text": "I think about World War II --", "start": 137.26, "duration": 2.0}, {"text": "some of our great technologists then,", "start": 139.26, "duration": 2.0}, {"text": "some of our great physicists,", "start": 141.26, "duration": 2.0}, {"text": "studying nuclear fission and fusion --", "start": 143.26, "duration": 2.0}, {"text": "just nuclear stuff.", "start": 145.26, "duration": 2.0}, {"text": "We gather together these physicists in Los Alamos", "start": 147.26, "duration": 3.0}, {"text": "to see what they'll build.", "start": 150.26, "duration": 3.0}, {"text": "We want the people building the technology", "start": 153.26, "duration": 3.0}, {"text": "thinking about what we should be doing with the technology.", "start": 156.26, "duration": 3.0}, {"text": "So what should we be doing with that guy's data?", "start": 161.26, "duration": 3.0}, {"text": "Should we be collecting it, gathering it,", "start": 164.26, "duration": 3.0}, {"text": "so we can make his online experience better?", "start": 167.26, "duration": 2.0}, {"text": "So we can make money?", "start": 169.26, "duration": 2.0}, {"text": "So we can protect ourselves", "start": 171.26, "duration": 2.0}, {"text": "if he was up to no good?", "start": 173.26, "duration": 2.0}, {"text": "Or should we respect his privacy,", "start": 175.26, "duration": 3.0}, {"text": "protect his dignity and leave him alone?", "start": 178.26, "duration": 3.0}, {"text": "Which one is it?", "start": 182.26, "duration": 3.0}, {"text": "How should we figure it out?", "start": 185.26, "duration": 2.0}, {"text": "I know: crowdsource. Let's crowdsource this.", "start": 187.26, "duration": 3.0}, {"text": "So to get people warmed up,", "start": 191.26, "duration": 3.0}, {"text": "let's start with an easy question --", "start": 194.26, "duration": 2.0}, {"text": "something I'm sure everybody here has an opinion about:", "start": 196.26, "duration": 3.0}, {"text": "iPhone versus Android.", "start": 199.26, "duration": 2.0}, {"text": "Let's do a show of hands -- iPhone.", "start": 201.26, "duration": 3.0}, {"text": "Uh huh.", "start": 204.26, "duration": 2.0}, {"text": "Android.", "start": 206.26, "duration": 3.0}, {"text": "You'd think with a bunch of smart people", "start": 209.26, "duration": 2.0}, {"text": "we wouldn't be such suckers just for the pretty phones.", "start": 211.26, "duration": 2.0}, {"text": "(Laughter)", "start": 213.26, "duration": 2.0}, {"text": "Next question,", "start": 215.26, "duration": 2.0}, {"text": "a little bit harder.", "start": 217.26, "duration": 2.0}, {"text": "Should we be collecting all of that guy's data", "start": 219.26, "duration": 2.0}, {"text": "to make his experiences better", "start": 221.26, "duration": 2.0}, {"text": "and to protect ourselves in case he's up to no good?", "start": 223.26, "duration": 3.0}, {"text": "Or should we leave him alone?", "start": 226.26, "duration": 2.0}, {"text": "Collect his data.", "start": 228.26, "duration": 3.0}, {"text": "Leave him alone.", "start": 233.26, "duration": 3.0}, {"text": "You're safe. It's fine.", "start": 236.26, "duration": 2.0}, {"text": "(Laughter)", "start": 238.26, "duration": 2.0}, {"text": "Okay, last question --", "start": 240.26, "duration": 2.0}, {"text": "harder question --", "start": 242.26, "duration": 2.0}, {"text": "when trying to evaluate", "start": 244.26, "duration": 3.0}, {"text": "what we should do in this case,", "start": 247.26, "duration": 3.0}, {"text": "should we use a Kantian deontological moral framework,", "start": 250.26, "duration": 4.0}, {"text": "or should we use a Millian consequentialist one?", "start": 254.26, "duration": 3.0}, {"text": "Kant.", "start": 259.26, "duration": 3.0}, {"text": "Mill.", "start": 262.26, "duration": 3.0}, {"text": "Not as many votes.", "start": 265.26, "duration": 2.0}, {"text": "(Laughter)", "start": 267.26, "duration": 3.0}, {"text": "Yeah, that's a terrifying result.", "start": 270.26, "duration": 3.0}, {"text": "Terrifying, because we have stronger opinions", "start": 274.26, "duration": 4.0}, {"text": "about our hand-held devices", "start": 278.26, "duration": 2.0}, {"text": "than about the moral framework", "start": 280.26, "duration": 2.0}, {"text": "we should use to guide our decisions.", "start": 282.26, "duration": 2.0}, {"text": "How do we know what to do with all the power we have", "start": 284.26, "duration": 3.0}, {"text": "if we don't have a moral framework?", "start": 287.26, "duration": 3.0}, {"text": "We know more about mobile operating systems,", "start": 290.26, "duration": 3.0}, {"text": "but what we really need is a moral operating system.", "start": 293.26, "duration": 3.0}, {"text": "What's a moral operating system?", "start": 298.26, "duration": 2.0}, {"text": "We all know right and wrong, right?", "start": 300.26, "duration": 2.0}, {"text": "You feel good when you do something right,", "start": 302.26, "duration": 2.0}, {"text": "you feel bad when you do something wrong.", "start": 304.26, "duration": 2.0}, {"text": "Our parents teach us that: praise with the good, scold with the bad.", "start": 306.26, "duration": 3.0}, {"text": "But how do we figure out what's right and wrong?", "start": 309.26, "duration": 3.0}, {"text": "And from day to day, we have the techniques that we use.", "start": 312.26, "duration": 3.0}, {"text": "Maybe we just follow our gut.", "start": 315.26, "duration": 3.0}, {"text": "Maybe we take a vote -- we crowdsource.", "start": 318.26, "duration": 3.0}, {"text": "Or maybe we punt --", "start": 321.26, "duration": 2.0}, {"text": "ask the legal department, see what they say.", "start": 323.26, "duration": 3.0}, {"text": "In other words, it's kind of random,", "start": 326.26, "duration": 2.0}, {"text": "kind of ad hoc,", "start": 328.26, "duration": 2.0}, {"text": "how we figure out what we should do.", "start": 330.26, "duration": 3.0}, {"text": "And maybe, if we want to be on surer footing,", "start": 333.26, "duration": 3.0}, {"text": "what we really want is a moral framework that will help guide us there,", "start": 336.26, "duration": 3.0}, {"text": "that will tell us what kinds of things are right and wrong in the first place,", "start": 339.26, "duration": 3.0}, {"text": "and how would we know in a given situation what to do.", "start": 342.26, "duration": 4.0}, {"text": "So let's get a moral framework.", "start": 346.26, "duration": 2.0}, {"text": "We're numbers people, living by numbers.", "start": 348.26, "duration": 3.0}, {"text": "How can we use numbers", "start": 351.26, "duration": 2.0}, {"text": "as the basis for a moral framework?", "start": 353.26, "duration": 3.0}, {"text": "I know a guy who did exactly that.", "start": 356.26, "duration": 3.0}, {"text": "A brilliant guy --", "start": 359.26, "duration": 3.0}, {"text": "he's been dead 2,500 years.", "start": 362.26, "duration": 3.0}, {"text": "Plato, that's right.", "start": 365.26, "duration": 2.0}, {"text": "Remember him -- old philosopher?", "start": 367.26, "duration": 2.0}, {"text": "You were sleeping during that class.", "start": 369.26, "duration": 3.0}, {"text": "And Plato, he had a lot of the same concerns that we did.", "start": 372.26, "duration": 2.0}, {"text": "He was worried about right and wrong.", "start": 374.26, "duration": 2.0}, {"text": "He wanted to know what is just.", "start": 376.26, "duration": 2.0}, {"text": "But he was worried that all we seem to be doing", "start": 378.26, "duration": 2.0}, {"text": "is trading opinions about this.", "start": 380.26, "duration": 2.0}, {"text": "He says something's just. She says something else is just.", "start": 382.26, "duration": 3.0}, {"text": "It's kind of convincing when he talks and when she talks too.", "start": 385.26, "duration": 2.0}, {"text": "I'm just going back and forth; I'm not getting anywhere.", "start": 387.26, "duration": 2.0}, {"text": "I don't want opinions; I want knowledge.", "start": 389.26, "duration": 3.0}, {"text": "I want to know the truth about justice --", "start": 392.26, "duration": 3.0}, {"text": "like we have truths in math.", "start": 395.26, "duration": 3.0}, {"text": "In math, we know the objective facts.", "start": 398.26, "duration": 3.0}, {"text": "Take a number, any number -- two.", "start": 401.26, "duration": 2.0}, {"text": "Favorite number. I love that number.", "start": 403.26, "duration": 2.0}, {"text": "There are truths about two.", "start": 405.26, "duration": 2.0}, {"text": "If you've got two of something,", "start": 407.26, "duration": 2.0}, {"text": "you add two more, you get four.", "start": 409.26, "duration": 2.0}, {"text": "That's true no matter what thing you're talking about.", "start": 411.26, "duration": 2.0}, {"text": "It's an objective truth about the form of two,", "start": 413.26, "duration": 2.0}, {"text": "the abstract form.", "start": 415.26, "duration": 2.0}, {"text": "When you have two of anything -- two eyes, two ears, two noses,", "start": 417.26, "duration": 2.0}, {"text": "just two protrusions --", "start": 419.26, "duration": 2.0}, {"text": "those all partake of the form of two.", "start": 421.26, "duration": 3.0}, {"text": "They all participate in the truths that two has.", "start": 424.26, "duration": 4.0}, {"text": "They all have two-ness in them.", "start": 428.26, "duration": 2.0}, {"text": "And therefore, it's not a matter of opinion.", "start": 430.26, "duration": 3.0}, {"text": "What if, Plato thought,", "start": 433.26, "duration": 2.0}, {"text": "ethics was like math?", "start": 435.26, "duration": 2.0}, {"text": "What if there were a pure form of justice?", "start": 437.26, "duration": 3.0}, {"text": "What if there are truths about justice,", "start": 440.26, "duration": 2.0}, {"text": "and you could just look around in this world", "start": 442.26, "duration": 2.0}, {"text": "and see which things participated,", "start": 444.26, "duration": 2.0}, {"text": "partook of that form of justice?", "start": 446.26, "duration": 3.0}, {"text": "Then you would know what was really just and what wasn't.", "start": 449.26, "duration": 3.0}, {"text": "It wouldn't be a matter", "start": 452.26, "duration": 2.0}, {"text": "of just opinion or just appearances.", "start": 454.26, "duration": 3.0}, {"text": "That's a stunning vision.", "start": 457.26, "duration": 2.0}, {"text": "I mean, think about that. How grand. How ambitious.", "start": 459.26, "duration": 3.0}, {"text": "That's as ambitious as we are.", "start": 462.26, "duration": 2.0}, {"text": "He wants to solve ethics.", "start": 464.26, "duration": 2.0}, {"text": "He wants objective truths.", "start": 466.26, "duration": 2.0}, {"text": "If you think that way,", "start": 468.26, "duration": 3.0}, {"text": "you have a Platonist moral framework.", "start": 471.26, "duration": 3.0}, {"text": "If you don't think that way,", "start": 474.26, "duration": 2.0}, {"text": "well, you have a lot of company in the history of Western philosophy,", "start": 476.26, "duration": 2.0}, {"text": "because the tidy idea, you know, people criticized it.", "start": 478.26, "duration": 3.0}, {"text": "Aristotle, in particular, he was not amused.", "start": 481.26, "duration": 3.0}, {"text": "He thought it was impractical.", "start": 484.26, "duration": 3.0}, {"text": "Aristotle said, \"We should seek only so much precision in each subject", "start": 487.26, "duration": 4.0}, {"text": "as that subject allows.\"", "start": 491.26, "duration": 2.0}, {"text": "Aristotle thought ethics wasn't a lot like math.", "start": 493.26, "duration": 3.0}, {"text": "He thought ethics was a matter of making decisions in the here-and-now", "start": 496.26, "duration": 3.0}, {"text": "using our best judgment", "start": 499.26, "duration": 2.0}, {"text": "to find the right path.", "start": 501.26, "duration": 2.0}, {"text": "If you think that, Plato's not your guy.", "start": 503.26, "duration": 2.0}, {"text": "But don't give up.", "start": 505.26, "duration": 2.0}, {"text": "Maybe there's another way", "start": 507.26, "duration": 2.0}, {"text": "that we can use numbers as the basis of our moral framework.", "start": 509.26, "duration": 3.0}, {"text": "How about this:", "start": 513.26, "duration": 2.0}, {"text": "What if in any situation you could just calculate,", "start": 515.26, "duration": 3.0}, {"text": "look at the choices,", "start": 518.26, "duration": 2.0}, {"text": "measure out which one's better and know what to do?", "start": 520.26, "duration": 3.0}, {"text": "That sound familiar?", "start": 523.26, "duration": 2.0}, {"text": "That's a utilitarian moral framework.", "start": 525.26, "duration": 3.0}, {"text": "John Stuart Mill was a great advocate of this --", "start": 528.26, "duration": 2.0}, {"text": "nice guy besides --", "start": 530.26, "duration": 2.0}, {"text": "and only been dead 200 years.", "start": 532.26, "duration": 2.0}, {"text": "So basis of utilitarianism --", "start": 534.26, "duration": 2.0}, {"text": "I'm sure you're familiar at least.", "start": 536.26, "duration": 2.0}, {"text": "The three people who voted for Mill before are familiar with this.", "start": 538.26, "duration": 2.0}, {"text": "But here's the way it works.", "start": 540.26, "duration": 2.0}, {"text": "What if morals, what if what makes something moral", "start": 542.26, "duration": 3.0}, {"text": "is just a matter of if it maximizes pleasure", "start": 545.26, "duration": 2.0}, {"text": "and minimizes pain?", "start": 547.26, "duration": 2.0}, {"text": "It does something intrinsic to the act.", "start": 549.26, "duration": 3.0}, {"text": "It's not like its relation to some abstract form.", "start": 552.26, "duration": 2.0}, {"text": "It's just a matter of the consequences.", "start": 554.26, "duration": 2.0}, {"text": "You just look at the consequences", "start": 556.26, "duration": 2.0}, {"text": "and see if, overall, it's for the good or for the worse.", "start": 558.26, "duration": 2.0}, {"text": "That would be simple. Then we know what to do.", "start": 560.26, "duration": 2.0}, {"text": "Let's take an example.", "start": 562.26, "duration": 2.0}, {"text": "Suppose I go up", "start": 564.26, "duration": 2.0}, {"text": "and I say, \"I'm going to take your phone.\"", "start": 566.26, "duration": 2.0}, {"text": "Not just because it rang earlier,", "start": 568.26, "duration": 2.0}, {"text": "but I'm going to take it because I made a little calculation.", "start": 570.26, "duration": 3.0}, {"text": "I thought, that guy looks suspicious.", "start": 573.26, "duration": 3.0}, {"text": "And what if he's been sending little messages to Bin Laden's hideout --", "start": 576.26, "duration": 3.0}, {"text": "or whoever took over after Bin Laden --", "start": 579.26, "duration": 2.0}, {"text": "and he's actually like a terrorist, a sleeper cell.", "start": 581.26, "duration": 3.0}, {"text": "I'm going to find that out, and when I find that out,", "start": 584.26, "duration": 3.0}, {"text": "I'm going to prevent a huge amount of damage that he could cause.", "start": 587.26, "duration": 3.0}, {"text": "That has a very high utility to prevent that damage.", "start": 590.26, "duration": 3.0}, {"text": "And compared to the little pain that it's going to cause --", "start": 593.26, "duration": 2.0}, {"text": "because it's going to be embarrassing when I'm looking on his phone", "start": 595.26, "duration": 2.0}, {"text": "and seeing that he has a Farmville problem and that whole bit --", "start": 597.26, "duration": 3.0}, {"text": "that's overwhelmed", "start": 600.26, "duration": 3.0}, {"text": "by the value of looking at the phone.", "start": 603.26, "duration": 2.0}, {"text": "If you feel that way,", "start": 605.26, "duration": 2.0}, {"text": "that's a utilitarian choice.", "start": 607.26, "duration": 3.0}, {"text": "But maybe you don't feel that way either.", "start": 610.26, "duration": 3.0}, {"text": "Maybe you think, it's his phone.", "start": 613.26, "duration": 2.0}, {"text": "It's wrong to take his phone", "start": 615.26, "duration": 2.0}, {"text": "because he's a person", "start": 617.26, "duration": 2.0}, {"text": "and he has rights and he has dignity,", "start": 619.26, "duration": 2.0}, {"text": "and we can't just interfere with that.", "start": 621.26, "duration": 2.0}, {"text": "He has autonomy.", "start": 623.26, "duration": 2.0}, {"text": "It doesn't matter what the calculations are.", "start": 625.26, "duration": 2.0}, {"text": "There are things that are intrinsically wrong --", "start": 627.26, "duration": 3.0}, {"text": "like lying is wrong,", "start": 630.26, "duration": 2.0}, {"text": "like torturing innocent children is wrong.", "start": 632.26, "duration": 3.0}, {"text": "Kant was very good on this point,", "start": 635.26, "duration": 3.0}, {"text": "and he said it a little better than I'll say it.", "start": 638.26, "duration": 2.0}, {"text": "He said we should use our reason", "start": 640.26, "duration": 2.0}, {"text": "to figure out the rules by which we should guide our conduct,", "start": 642.26, "duration": 3.0}, {"text": "and then it is our duty to follow those rules.", "start": 645.26, "duration": 3.0}, {"text": "It's not a matter of calculation.", "start": 648.26, "duration": 3.0}, {"text": "So let's stop.", "start": 651.26, "duration": 2.0}, {"text": "We're right in the thick of it, this philosophical thicket.", "start": 653.26, "duration": 3.0}, {"text": "And this goes on for thousands of years,", "start": 656.26, "duration": 3.0}, {"text": "because these are hard questions,", "start": 659.26, "duration": 2.0}, {"text": "and I've only got 15 minutes.", "start": 661.26, "duration": 2.0}, {"text": "So let's cut to the chase.", "start": 663.26, "duration": 2.0}, {"text": "How should we be making our decisions?", "start": 665.26, "duration": 4.0}, {"text": "Is it Plato, is it Aristotle, is it Kant, is it Mill?", "start": 669.26, "duration": 3.0}, {"text": "What should we be doing? What's the answer?", "start": 672.26, "duration": 2.0}, {"text": "What's the formula that we can use in any situation", "start": 674.26, "duration": 3.0}, {"text": "to determine what we should do,", "start": 677.26, "duration": 2.0}, {"text": "whether we should use that guy's data or not?", "start": 679.26, "duration": 2.0}, {"text": "What's the formula?", "start": 681.26, "duration": 3.0}, {"text": "There's not a formula.", "start": 685.26, "duration": 2.0}, {"text": "There's not a simple answer.", "start": 689.26, "duration": 2.0}, {"text": "Ethics is hard.", "start": 691.26, "duration": 3.0}, {"text": "Ethics requires thinking.", "start": 694.26, "duration": 3.0}, {"text": "And that's uncomfortable.", "start": 698.26, "duration": 2.0}, {"text": "I know; I spent a lot of my career", "start": 700.26, "duration": 2.0}, {"text": "in artificial intelligence,", "start": 702.26, "duration": 2.0}, {"text": "trying to build machines that could do some of this thinking for us,", "start": 704.26, "duration": 3.0}, {"text": "that could give us answers.", "start": 707.26, "duration": 2.0}, {"text": "But they can't.", "start": 709.26, "duration": 2.0}, {"text": "You can't just take human thinking", "start": 711.26, "duration": 2.0}, {"text": "and put it into a machine.", "start": 713.26, "duration": 2.0}, {"text": "We're the ones who have to do it.", "start": 715.26, "duration": 3.0}, {"text": "Happily, we're not machines, and we can do it.", "start": 718.26, "duration": 3.0}, {"text": "Not only can we think,", "start": 721.26, "duration": 2.0}, {"text": "we must.", "start": 723.26, "duration": 2.0}, {"text": "Hannah Arendt said,", "start": 725.26, "duration": 2.0}, {"text": "\"The sad truth", "start": 727.26, "duration": 2.0}, {"text": "is that most evil done in this world", "start": 729.26, "duration": 2.0}, {"text": "is not done by people", "start": 731.26, "duration": 2.0}, {"text": "who choose to be evil.", "start": 733.26, "duration": 2.0}, {"text": "It arises from not thinking.\"", "start": 735.26, "duration": 3.0}, {"text": "That's what she called the \"banality of evil.\"", "start": 738.26, "duration": 4.0}, {"text": "And the response to that", "start": 742.26, "duration": 2.0}, {"text": "is that we demand the exercise of thinking", "start": 744.26, "duration": 2.0}, {"text": "from every sane person.", "start": 746.26, "duration": 3.0}, {"text": "So let's do that. Let's think.", "start": 749.26, "duration": 2.0}, {"text": "In fact, let's start right now.", "start": 751.26, "duration": 3.0}, {"text": "Every person in this room do this:", "start": 754.26, "duration": 3.0}, {"text": "think of the last time you had a decision to make", "start": 757.26, "duration": 3.0}, {"text": "where you were worried to do the right thing,", "start": 760.26, "duration": 2.0}, {"text": "where you wondered, \"What should I be doing?\"", "start": 762.26, "duration": 2.0}, {"text": "Bring that to mind,", "start": 764.26, "duration": 2.0}, {"text": "and now reflect on that", "start": 766.26, "duration": 2.0}, {"text": "and say, \"How did I come up that decision?", "start": 768.26, "duration": 3.0}, {"text": "What did I do? Did I follow my gut?", "start": 771.26, "duration": 3.0}, {"text": "Did I have somebody vote on it? Or did I punt to legal?\"", "start": 774.26, "duration": 2.0}, {"text": "Or now we have a few more choices.", "start": 776.26, "duration": 3.0}, {"text": "\"Did I evaluate what would be the highest pleasure", "start": 779.26, "duration": 2.0}, {"text": "like Mill would?", "start": 781.26, "duration": 2.0}, {"text": "Or like Kant, did I use reason to figure out what was intrinsically right?\"", "start": 783.26, "duration": 3.0}, {"text": "Think about it. Really bring it to mind. This is important.", "start": 786.26, "duration": 3.0}, {"text": "It is so important", "start": 789.26, "duration": 2.0}, {"text": "we are going to spend 30 seconds of valuable TEDTalk time", "start": 791.26, "duration": 2.0}, {"text": "doing nothing but thinking about this.", "start": 793.26, "duration": 2.0}, {"text": "Are you ready? Go.", "start": 795.26, "duration": 2.0}, {"text": "Stop. Good work.", "start": 813.26, "duration": 3.0}, {"text": "What you just did,", "start": 816.26, "duration": 2.0}, {"text": "that's the first step towards taking responsibility", "start": 818.26, "duration": 2.0}, {"text": "for what we should do with all of our power.", "start": 820.26, "duration": 3.0}, {"text": "Now the next step -- try this.", "start": 825.26, "duration": 3.0}, {"text": "Go find a friend and explain to them", "start": 829.26, "duration": 2.0}, {"text": "how you made that decision.", "start": 831.26, "duration": 2.0}, {"text": "Not right now. Wait till I finish talking.", "start": 833.26, "duration": 2.0}, {"text": "Do it over lunch.", "start": 835.26, "duration": 2.0}, {"text": "And don't just find another technologist friend;", "start": 837.26, "duration": 3.0}, {"text": "find somebody different than you.", "start": 840.26, "duration": 2.0}, {"text": "Find an artist or a writer --", "start": 842.26, "duration": 2.0}, {"text": "or, heaven forbid, find a philosopher and talk to them.", "start": 844.26, "duration": 3.0}, {"text": "In fact, find somebody from the humanities.", "start": 847.26, "duration": 2.0}, {"text": "Why? Because they think about problems", "start": 849.26, "duration": 2.0}, {"text": "differently than we do as technologists.", "start": 851.26, "duration": 2.0}, {"text": "Just a few days ago, right across the street from here,", "start": 853.26, "duration": 3.0}, {"text": "there was hundreds of people gathered together.", "start": 856.26, "duration": 2.0}, {"text": "It was technologists and humanists", "start": 858.26, "duration": 2.0}, {"text": "at that big BiblioTech Conference.", "start": 860.26, "duration": 2.0}, {"text": "And they gathered together", "start": 862.26, "duration": 2.0}, {"text": "because the technologists wanted to learn", "start": 864.26, "duration": 2.0}, {"text": "what it would be like to think from a humanities perspective.", "start": 866.26, "duration": 3.0}, {"text": "You have someone from Google", "start": 869.26, "duration": 2.0}, {"text": "talking to someone who does comparative literature.", "start": 871.26, "duration": 2.0}, {"text": "You're thinking about the relevance of 17th century French theater --", "start": 873.26, "duration": 3.0}, {"text": "how does that bear upon venture capital?", "start": 876.26, "duration": 2.0}, {"text": "Well that's interesting. That's a different way of thinking.", "start": 878.26, "duration": 3.0}, {"text": "And when you think in that way,", "start": 881.26, "duration": 2.0}, {"text": "you become more sensitive to the human considerations,", "start": 883.26, "duration": 3.0}, {"text": "which are crucial to making ethical decisions.", "start": 886.26, "duration": 3.0}, {"text": "So imagine that right now", "start": 889.26, "duration": 2.0}, {"text": "you went and you found your musician friend.", "start": 891.26, "duration": 2.0}, {"text": "And you're telling him what we're talking about,", "start": 893.26, "duration": 3.0}, {"text": "about our whole data revolution and all this --", "start": 896.26, "duration": 2.0}, {"text": "maybe even hum a few bars of our theme music.", "start": 898.26, "duration": 2.0}, {"text": "\u266b Dum ta da da dum dum ta da da dum \u266b", "start": 900.26, "duration": 3.0}, {"text": "Well, your musician friend will stop you and say,", "start": 903.26, "duration": 2.0}, {"text": "\"You know, the theme music", "start": 905.26, "duration": 2.0}, {"text": "for your data revolution,", "start": 907.26, "duration": 2.0}, {"text": "that's an opera, that's Wagner.", "start": 909.26, "duration": 2.0}, {"text": "It's based on Norse legend.", "start": 911.26, "duration": 2.0}, {"text": "It's Gods and mythical creatures", "start": 913.26, "duration": 2.0}, {"text": "fighting over magical jewelry.\"", "start": 915.26, "duration": 3.0}, {"text": "That's interesting.", "start": 919.26, "duration": 3.0}, {"text": "Now it's also a beautiful opera,", "start": 922.26, "duration": 3.0}, {"text": "and we're moved by that opera.", "start": 925.26, "duration": 3.0}, {"text": "We're moved because it's about the battle", "start": 928.26, "duration": 2.0}, {"text": "between good and evil,", "start": 930.26, "duration": 2.0}, {"text": "about right and wrong.", "start": 932.26, "duration": 2.0}, {"text": "And we care about right and wrong.", "start": 934.26, "duration": 2.0}, {"text": "We care what happens in that opera.", "start": 936.26, "duration": 3.0}, {"text": "We care what happens in \"Apocalypse Now.\"", "start": 939.26, "duration": 3.0}, {"text": "And we certainly care", "start": 942.26, "duration": 2.0}, {"text": "what happens with our technologies.", "start": 944.26, "duration": 2.0}, {"text": "We have so much power today,", "start": 946.26, "duration": 2.0}, {"text": "it is up to us to figure out what to do,", "start": 948.26, "duration": 3.0}, {"text": "and that's the good news.", "start": 951.26, "duration": 2.0}, {"text": "We're the ones writing this opera.", "start": 953.26, "duration": 3.0}, {"text": "This is our movie.", "start": 956.26, "duration": 2.0}, {"text": "We figure out what will happen with this technology.", "start": 958.26, "duration": 3.0}, {"text": "We determine how this will all end.", "start": 961.26, "duration": 3.0}, {"text": "Thank you.", "start": 964.26, "duration": 2.0}, {"text": "(Applause)", "start": 966.26, "duration": 5.0}]