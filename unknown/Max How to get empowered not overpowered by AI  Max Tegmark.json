[{"text": "After 13.8 billion years\nof cosmic history,", "start": 12.76, "duration": 4.416}, {"text": "our universe has woken up", "start": 17.2, "duration": 2.096}, {"text": "and become aware of itself.", "start": 19.32, "duration": 1.52}, {"text": "From a small blue planet,", "start": 21.48, "duration": 1.936}, {"text": "tiny, conscious parts of our universe\nhave begun gazing out into the cosmos", "start": 23.44, "duration": 4.136}, {"text": "with telescopes,", "start": 27.6, "duration": 1.376}, {"text": "discovering something humbling.", "start": 29.0, "duration": 1.48}, {"text": "We've discovered that our universe\nis vastly grander", "start": 31.32, "duration": 2.896}, {"text": "than our ancestors imagined", "start": 34.24, "duration": 1.336}, {"text": "and that life seems to be an almost\nimperceptibly small perturbation", "start": 35.6, "duration": 4.256}, {"text": "on an otherwise dead universe.", "start": 39.88, "duration": 1.72}, {"text": "But we've also discovered\nsomething inspiring,", "start": 42.32, "duration": 3.016}, {"text": "which is that the technology\nwe're developing has the potential", "start": 45.36, "duration": 2.976}, {"text": "to help life flourish like never before,", "start": 48.36, "duration": 2.856}, {"text": "not just for centuries\nbut for billions of years,", "start": 51.24, "duration": 3.096}, {"text": "and not just on earth but throughout\nmuch of this amazing cosmos.", "start": 54.36, "duration": 4.12}, {"text": "I think of the earliest life as \"Life 1.0\"", "start": 59.68, "duration": 3.336}, {"text": "because it was really dumb,", "start": 63.04, "duration": 1.376}, {"text": "like bacteria, unable to learn\nanything during its lifetime.", "start": 64.44, "duration": 4.296}, {"text": "I think of us humans as \"Life 2.0\"\nbecause we can learn,", "start": 68.76, "duration": 3.376}, {"text": "which we in nerdy, geek speak,", "start": 72.16, "duration": 1.496}, {"text": "might think of as installing\nnew software into our brains,", "start": 73.68, "duration": 3.216}, {"text": "like languages and job skills.", "start": 76.92, "duration": 2.12}, {"text": "\"Life 3.0,\" which can design not only\nits software but also its hardware", "start": 79.68, "duration": 4.296}, {"text": "of course doesn't exist yet.", "start": 84.0, "duration": 1.656}, {"text": "But perhaps our technology\nhas already made us \"Life 2.1,\"", "start": 85.68, "duration": 3.776}, {"text": "with our artificial knees,\npacemakers and cochlear implants.", "start": 89.48, "duration": 4.336}, {"text": "So let's take a closer look\nat our relationship with technology, OK?", "start": 93.84, "duration": 3.88}, {"text": "As an example,", "start": 98.8, "duration": 1.216}, {"text": "the Apollo 11 moon mission\nwas both successful and inspiring,", "start": 100.04, "duration": 5.296}, {"text": "showing that when we humans\nuse technology wisely,", "start": 105.36, "duration": 3.016}, {"text": "we can accomplish things\nthat our ancestors could only dream of.", "start": 108.4, "duration": 3.936}, {"text": "But there's an even more inspiring journey", "start": 112.36, "duration": 2.976}, {"text": "propelled by something\nmore powerful than rocket engines,", "start": 115.36, "duration": 2.68}, {"text": "where the passengers\naren't just three astronauts", "start": 119.2, "duration": 2.336}, {"text": "but all of humanity.", "start": 121.56, "duration": 1.776}, {"text": "Let's talk about our collective\njourney into the future", "start": 123.36, "duration": 2.936}, {"text": "with artificial intelligence.", "start": 126.32, "duration": 2.0}, {"text": "My friend Jaan Tallinn likes to point out\nthat just as with rocketry,", "start": 128.96, "duration": 4.536}, {"text": "it's not enough to make\nour technology powerful.", "start": 133.52, "duration": 3.16}, {"text": "We also have to figure out,\nif we're going to be really ambitious,", "start": 137.56, "duration": 3.175}, {"text": "how to steer it", "start": 140.759, "duration": 1.416}, {"text": "and where we want to go with it.", "start": 142.199, "duration": 1.681}, {"text": "So let's talk about all three\nfor artificial intelligence:", "start": 144.88, "duration": 2.84}, {"text": "the power, the steering\nand the destination.", "start": 148.44, "duration": 3.056}, {"text": "Let's start with the power.", "start": 151.52, "duration": 1.286}, {"text": "I define intelligence very inclusively --", "start": 153.6, "duration": 3.096}, {"text": "simply as our ability\nto accomplish complex goals,", "start": 156.72, "duration": 4.336}, {"text": "because I want to include both\nbiological and artificial intelligence.", "start": 161.08, "duration": 3.816}, {"text": "And I want to avoid\nthe silly carbon-chauvinism idea", "start": 164.92, "duration": 4.016}, {"text": "that you can only be smart\nif you're made of meat.", "start": 168.96, "duration": 2.36}, {"text": "It's really amazing how the power\nof AI has grown recently.", "start": 172.88, "duration": 4.176}, {"text": "Just think about it.", "start": 177.08, "duration": 1.256}, {"text": "Not long ago, robots couldn't walk.", "start": 178.36, "duration": 3.2}, {"text": "Now, they can do backflips.", "start": 183.04, "duration": 1.72}, {"text": "Not long ago,", "start": 186.08, "duration": 1.816}, {"text": "we didn't have self-driving cars.", "start": 187.92, "duration": 1.76}, {"text": "Now, we have self-flying rockets.", "start": 190.92, "duration": 2.48}, {"text": "Not long ago,", "start": 195.96, "duration": 1.416}, {"text": "AI couldn't do face recognition.", "start": 197.4, "duration": 2.616}, {"text": "Now, AI can generate fake faces", "start": 200.04, "duration": 2.976}, {"text": "and simulate your face\nsaying stuff that you never said.", "start": 203.04, "duration": 4.16}, {"text": "Not long ago,", "start": 208.4, "duration": 1.576}, {"text": "AI couldn't beat us at the game of Go.", "start": 210.0, "duration": 1.88}, {"text": "Then, Google DeepMind's AlphaZero AI\ntook 3,000 years of human Go games", "start": 212.4, "duration": 5.096}, {"text": "and Go wisdom,", "start": 217.52, "duration": 1.256}, {"text": "ignored it all and became the world's best\nplayer by just playing against itself.", "start": 218.8, "duration": 4.976}, {"text": "And the most impressive feat here\nwasn't that it crushed human gamers,", "start": 223.8, "duration": 3.696}, {"text": "but that it crushed human AI researchers", "start": 227.52, "duration": 2.576}, {"text": "who had spent decades\nhandcrafting game-playing software.", "start": 230.12, "duration": 3.68}, {"text": "And AlphaZero crushed human AI researchers\nnot just in Go but even at chess,", "start": 234.2, "duration": 4.656}, {"text": "which we have been working on since 1950.", "start": 238.88, "duration": 2.48}, {"text": "So all this amazing recent progress in AI\nreally begs the question:", "start": 242.0, "duration": 4.24}, {"text": "How far will it go?", "start": 247.28, "duration": 1.56}, {"text": "I like to think about this question", "start": 249.8, "duration": 1.696}, {"text": "in terms of this abstract\nlandscape of tasks,", "start": 251.52, "duration": 2.976}, {"text": "where the elevation represents\nhow hard it is for AI to do each task", "start": 254.52, "duration": 3.456}, {"text": "at human level,", "start": 258.0, "duration": 1.216}, {"text": "and the sea level represents\nwhat AI can do today.", "start": 259.24, "duration": 2.76}, {"text": "The sea level is rising\nas AI improves,", "start": 263.12, "duration": 2.056}, {"text": "so there's a kind of global warming\ngoing on here in the task landscape.", "start": 265.2, "duration": 3.44}, {"text": "And the obvious takeaway\nis to avoid careers at the waterfront --", "start": 270.04, "duration": 3.335}, {"text": "(Laughter)", "start": 273.399, "duration": 1.257}, {"text": "which will soon be\nautomated and disrupted.", "start": 274.68, "duration": 2.856}, {"text": "But there's a much\nbigger question as well.", "start": 277.56, "duration": 2.976}, {"text": "How high will the water end up rising?", "start": 280.56, "duration": 1.81}, {"text": "Will it eventually rise\nto flood everything,", "start": 283.44, "duration": 3.2}, {"text": "matching human intelligence at all tasks.", "start": 287.84, "duration": 2.496}, {"text": "This is the definition\nof artificial general intelligence --", "start": 290.36, "duration": 3.736}, {"text": "AGI,", "start": 294.12, "duration": 1.296}, {"text": "which has been the holy grail\nof AI research since its inception.", "start": 295.44, "duration": 3.08}, {"text": "By this definition, people who say,", "start": 299.0, "duration": 1.776}, {"text": "\"Ah, there will always be jobs\nthat humans can do better than machines,\"", "start": 300.8, "duration": 3.416}, {"text": "are simply saying\nthat we'll never get AGI.", "start": 304.24, "duration": 2.92}, {"text": "Sure, we might still choose\nto have some human jobs", "start": 307.68, "duration": 3.576}, {"text": "or to give humans income\nand purpose with our jobs,", "start": 311.28, "duration": 3.096}, {"text": "but AGI will in any case\ntransform life as we know it", "start": 314.4, "duration": 3.736}, {"text": "with humans no longer being\nthe most intelligent.", "start": 318.16, "duration": 2.736}, {"text": "Now, if the water level does reach AGI,", "start": 320.92, "duration": 3.696}, {"text": "then further AI progress will be driven\nmainly not by humans but by AI,", "start": 324.64, "duration": 5.296}, {"text": "which means that there's a possibility", "start": 329.96, "duration": 1.856}, {"text": "that further AI progress\ncould be way faster", "start": 331.84, "duration": 2.336}, {"text": "than the typical human research\nand development timescale of years,", "start": 334.2, "duration": 3.376}, {"text": "raising the controversial possibility\nof an intelligence explosion", "start": 337.6, "duration": 4.016}, {"text": "where recursively self-improving AI", "start": 341.64, "duration": 2.296}, {"text": "rapidly leaves human\nintelligence far behind,", "start": 343.96, "duration": 3.416}, {"text": "creating what's known\nas superintelligence.", "start": 347.4, "duration": 2.44}, {"text": "Alright, reality check:", "start": 351.8, "duration": 2.28}, {"text": "Are we going to get AGI any time soon?", "start": 355.12, "duration": 2.44}, {"text": "Some famous AI researchers,\nlike Rodney Brooks,", "start": 358.36, "duration": 2.696}, {"text": "think it won't happen\nfor hundreds of years.", "start": 361.08, "duration": 2.496}, {"text": "But others, like Google DeepMind\nfounder Demis Hassabis,", "start": 363.6, "duration": 3.896}, {"text": "are more optimistic", "start": 367.52, "duration": 1.256}, {"text": "and are working to try to make\nit happen much sooner.", "start": 368.8, "duration": 2.576}, {"text": "And recent surveys have shown\nthat most AI researchers", "start": 371.4, "duration": 3.296}, {"text": "actually share Demis's optimism,", "start": 374.72, "duration": 2.856}, {"text": "expecting that we will\nget AGI within decades,", "start": 377.6, "duration": 3.08}, {"text": "so within the lifetime of many of us,", "start": 381.64, "duration": 2.256}, {"text": "which begs the question -- and then what?", "start": 383.92, "duration": 1.96}, {"text": "What do we want the role of humans to be", "start": 387.04, "duration": 2.216}, {"text": "if machines can do everything better\nand cheaper than us?", "start": 389.28, "duration": 2.68}, {"text": "The way I see it, we face a choice.", "start": 395.0, "duration": 2.0}, {"text": "One option is to be complacent.", "start": 398.0, "duration": 1.576}, {"text": "We can say, \"Oh, let's just build machines\nthat can do everything we can do", "start": 399.6, "duration": 3.776}, {"text": "and not worry about the consequences.", "start": 403.4, "duration": 1.816}, {"text": "Come on, if we build technology\nthat makes all humans obsolete,", "start": 405.24, "duration": 3.256}, {"text": "what could possibly go wrong?\"", "start": 408.52, "duration": 2.096}, {"text": "(Laughter)", "start": 410.64, "duration": 1.656}, {"text": "But I think that would be\nembarrassingly lame.", "start": 412.32, "duration": 2.76}, {"text": "I think we should be more ambitious --\nin the spirit of TED.", "start": 416.08, "duration": 3.496}, {"text": "Let's envision a truly inspiring\nhigh-tech future", "start": 419.6, "duration": 3.496}, {"text": "and try to steer towards it.", "start": 423.12, "duration": 1.4}, {"text": "This brings us to the second part\nof our rocket metaphor: the steering.", "start": 425.72, "duration": 3.536}, {"text": "We're making AI more powerful,", "start": 429.28, "duration": 1.896}, {"text": "but how can we steer towards a future", "start": 431.2, "duration": 3.816}, {"text": "where AI helps humanity flourish\nrather than flounder?", "start": 435.04, "duration": 3.08}, {"text": "To help with this,", "start": 438.76, "duration": 1.256}, {"text": "I cofounded the Future of Life Institute.", "start": 440.04, "duration": 1.976}, {"text": "It's a small nonprofit promoting\nbeneficial technology use,", "start": 442.04, "duration": 2.776}, {"text": "and our goal is simply\nfor the future of life to exist", "start": 444.84, "duration": 2.736}, {"text": "and to be as inspiring as possible.", "start": 447.6, "duration": 2.056}, {"text": "You know, I love technology.", "start": 449.68, "duration": 3.176}, {"text": "Technology is why today\nis better than the Stone Age.", "start": 452.88, "duration": 2.92}, {"text": "And I'm optimistic that we can create\na really inspiring high-tech future ...", "start": 456.6, "duration": 4.08}, {"text": "if -- and this is a big if --", "start": 461.68, "duration": 1.456}, {"text": "if we win the wisdom race --", "start": 463.16, "duration": 2.456}, {"text": "the race between the growing\npower of our technology", "start": 465.64, "duration": 2.856}, {"text": "and the growing wisdom\nwith which we manage it.", "start": 468.52, "duration": 2.2}, {"text": "But this is going to require\na change of strategy", "start": 471.24, "duration": 2.296}, {"text": "because our old strategy\nhas been learning from mistakes.", "start": 473.56, "duration": 3.04}, {"text": "We invented fire,", "start": 477.28, "duration": 1.536}, {"text": "screwed up a bunch of times --", "start": 478.84, "duration": 1.536}, {"text": "invented the fire extinguisher.", "start": 480.4, "duration": 1.816}, {"text": "(Laughter)", "start": 482.24, "duration": 1.336}, {"text": "We invented the car,\nscrewed up a bunch of times --", "start": 483.6, "duration": 2.416}, {"text": "invented the traffic light,\nthe seat belt and the airbag,", "start": 486.04, "duration": 2.667}, {"text": "but with more powerful technology\nlike nuclear weapons and AGI,", "start": 488.731, "duration": 3.845}, {"text": "learning from mistakes\nis a lousy strategy,", "start": 492.6, "duration": 3.376}, {"text": "don't you think?", "start": 496.0, "duration": 1.216}, {"text": "(Laughter)", "start": 497.24, "duration": 1.016}, {"text": "It's much better to be proactive\nrather than reactive;", "start": 498.28, "duration": 2.576}, {"text": "plan ahead and get things\nright the first time", "start": 500.88, "duration": 2.296}, {"text": "because that might be\nthe only time we'll get.", "start": 503.2, "duration": 2.496}, {"text": "But it is funny because\nsometimes people tell me,", "start": 505.72, "duration": 2.336}, {"text": "\"Max, shhh, don't talk like that.", "start": 508.08, "duration": 2.736}, {"text": "That's Luddite scaremongering.\"", "start": 510.84, "duration": 1.72}, {"text": "But it's not scaremongering.", "start": 514.04, "duration": 1.536}, {"text": "It's what we at MIT\ncall safety engineering.", "start": 515.6, "duration": 2.88}, {"text": "Think about it:", "start": 519.2, "duration": 1.216}, {"text": "before NASA launched\nthe Apollo 11 mission,", "start": 520.44, "duration": 2.216}, {"text": "they systematically thought through\neverything that could go wrong", "start": 522.68, "duration": 3.136}, {"text": "when you put people\non top of explosive fuel tanks", "start": 525.84, "duration": 2.376}, {"text": "and launch them somewhere\nwhere no one could help them.", "start": 528.24, "duration": 2.616}, {"text": "And there was a lot that could go wrong.", "start": 530.88, "duration": 1.936}, {"text": "Was that scaremongering?", "start": 532.84, "duration": 1.48}, {"text": "No.", "start": 535.159, "duration": 1.217}, {"text": "That's was precisely\nthe safety engineering", "start": 536.4, "duration": 2.016}, {"text": "that ensured the success of the mission,", "start": 538.44, "duration": 1.936}, {"text": "and that is precisely the strategy\nI think we should take with AGI.", "start": 540.4, "duration": 4.176}, {"text": "Think through what can go wrong\nto make sure it goes right.", "start": 544.6, "duration": 4.056}, {"text": "So in this spirit,\nwe've organized conferences,", "start": 548.68, "duration": 2.536}, {"text": "bringing together leading\nAI researchers and other thinkers", "start": 551.24, "duration": 2.816}, {"text": "to discuss how to grow this wisdom\nwe need to keep AI beneficial.", "start": 554.08, "duration": 3.736}, {"text": "Our last conference\nwas in Asilomar, California last year", "start": 557.84, "duration": 3.296}, {"text": "and produced this list of 23 principles", "start": 561.16, "duration": 3.056}, {"text": "which have since been signed\nby over 1,000 AI researchers", "start": 564.24, "duration": 2.896}, {"text": "and key industry leaders,", "start": 567.16, "duration": 1.296}, {"text": "and I want to tell you\nabout three of these principles.", "start": 568.48, "duration": 3.176}, {"text": "One is that we should avoid an arms race\nand lethal autonomous weapons.", "start": 571.68, "duration": 4.96}, {"text": "The idea here is that any science\ncan be used for new ways of helping people", "start": 577.48, "duration": 3.616}, {"text": "or new ways of harming people.", "start": 581.12, "duration": 1.536}, {"text": "For example, biology and chemistry\nare much more likely to be used", "start": 582.68, "duration": 3.936}, {"text": "for new medicines or new cures\nthan for new ways of killing people,", "start": 586.64, "duration": 4.856}, {"text": "because biologists\nand chemists pushed hard --", "start": 591.52, "duration": 2.176}, {"text": "and successfully --", "start": 593.72, "duration": 1.256}, {"text": "for bans on biological\nand chemical weapons.", "start": 595.0, "duration": 2.176}, {"text": "And in the same spirit,", "start": 597.2, "duration": 1.256}, {"text": "most AI researchers want to stigmatize\nand ban lethal autonomous weapons.", "start": 598.48, "duration": 4.44}, {"text": "Another Asilomar AI principle", "start": 603.6, "duration": 1.816}, {"text": "is that we should mitigate\nAI-fueled income inequality.", "start": 605.44, "duration": 3.696}, {"text": "I think that if we can grow\nthe economic pie dramatically with AI", "start": 609.16, "duration": 4.456}, {"text": "and we still can't figure out\nhow to divide this pie", "start": 613.64, "duration": 2.456}, {"text": "so that everyone is better off,", "start": 616.12, "duration": 1.576}, {"text": "then shame on us.", "start": 617.72, "duration": 1.256}, {"text": "(Applause)", "start": 619.0, "duration": 4.096}, {"text": "Alright, now raise your hand\nif your computer has ever crashed.", "start": 623.12, "duration": 3.6}, {"text": "(Laughter)", "start": 627.48, "duration": 1.256}, {"text": "Wow, that's a lot of hands.", "start": 628.76, "duration": 1.656}, {"text": "Well, then you'll appreciate\nthis principle", "start": 630.44, "duration": 2.176}, {"text": "that we should invest much more\nin AI safety research,", "start": 632.64, "duration": 3.136}, {"text": "because as we put AI in charge\nof even more decisions and infrastructure,", "start": 635.8, "duration": 3.656}, {"text": "we need to figure out how to transform\ntoday's buggy and hackable computers", "start": 639.48, "duration": 3.616}, {"text": "into robust AI systems\nthat we can really trust,", "start": 643.12, "duration": 2.416}, {"text": "because otherwise,", "start": 645.56, "duration": 1.216}, {"text": "all this awesome new technology\ncan malfunction and harm us,", "start": 646.8, "duration": 2.816}, {"text": "or get hacked and be turned against us.", "start": 649.64, "duration": 1.976}, {"text": "And this AI safety work\nhas to include work on AI value alignment,", "start": 651.64, "duration": 5.696}, {"text": "because the real threat\nfrom AGI isn't malice,", "start": 657.36, "duration": 2.816}, {"text": "like in silly Hollywood movies,", "start": 660.2, "duration": 1.656}, {"text": "but competence --", "start": 661.88, "duration": 1.736}, {"text": "AGI accomplishing goals\nthat just aren't aligned with ours.", "start": 663.64, "duration": 3.416}, {"text": "For example, when we humans drove\nthe West African black rhino extinct,", "start": 667.08, "duration": 4.736}, {"text": "we didn't do it because we were a bunch\nof evil rhinoceros haters, did we?", "start": 671.84, "duration": 3.896}, {"text": "We did it because\nwe were smarter than them", "start": 675.76, "duration": 2.056}, {"text": "and our goals weren't aligned with theirs.", "start": 677.84, "duration": 2.576}, {"text": "But AGI is by definition smarter than us,", "start": 680.44, "duration": 2.656}, {"text": "so to make sure that we don't put\nourselves in the position of those rhinos", "start": 683.12, "duration": 3.576}, {"text": "if we create AGI,", "start": 686.72, "duration": 1.976}, {"text": "we need to figure out how\nto make machines understand our goals,", "start": 688.72, "duration": 4.176}, {"text": "adopt our goals and retain our goals.", "start": 692.92, "duration": 3.16}, {"text": "And whose goals should these be, anyway?", "start": 697.32, "duration": 2.856}, {"text": "Which goals should they be?", "start": 700.2, "duration": 1.896}, {"text": "This brings us to the third part\nof our rocket metaphor: the destination.", "start": 702.12, "duration": 3.56}, {"text": "We're making AI more powerful,", "start": 707.16, "duration": 1.856}, {"text": "trying to figure out how to steer it,", "start": 709.04, "duration": 1.816}, {"text": "but where do we want to go with it?", "start": 710.88, "duration": 1.68}, {"text": "This is the elephant in the room\nthat almost nobody talks about --", "start": 713.76, "duration": 3.656}, {"text": "not even here at TED --", "start": 717.44, "duration": 1.856}, {"text": "because we're so fixated\non short-term AI challenges.", "start": 719.32, "duration": 4.08}, {"text": "Look, our species is trying to build AGI,", "start": 724.08, "duration": 4.656}, {"text": "motivated by curiosity and economics,", "start": 728.76, "duration": 3.496}, {"text": "but what sort of future society\nare we hoping for if we succeed?", "start": 732.28, "duration": 3.68}, {"text": "We did an opinion poll on this recently,", "start": 736.68, "duration": 1.936}, {"text": "and I was struck to see", "start": 738.64, "duration": 1.216}, {"text": "that most people actually\nwant us to build superintelligence:", "start": 739.88, "duration": 2.896}, {"text": "AI that's vastly smarter\nthan us in all ways.", "start": 742.8, "duration": 3.16}, {"text": "What there was the greatest agreement on\nwas that we should be ambitious", "start": 747.12, "duration": 3.416}, {"text": "and help life spread into the cosmos,", "start": 750.56, "duration": 2.016}, {"text": "but there was much less agreement\nabout who or what should be in charge.", "start": 752.6, "duration": 4.496}, {"text": "And I was actually quite amused", "start": 757.12, "duration": 1.736}, {"text": "to see that there's some some people\nwho want it to be just machines.", "start": 758.88, "duration": 3.456}, {"text": "(Laughter)", "start": 762.36, "duration": 1.696}, {"text": "And there was total disagreement\nabout what the role of humans should be,", "start": 764.08, "duration": 3.856}, {"text": "even at the most basic level,", "start": 767.96, "duration": 1.976}, {"text": "so let's take a closer look\nat possible futures", "start": 769.96, "duration": 2.816}, {"text": "that we might choose\nto steer toward, alright?", "start": 772.8, "duration": 2.736}, {"text": "So don't get me wrong here.", "start": 775.56, "duration": 1.336}, {"text": "I'm not talking about space travel,", "start": 776.92, "duration": 2.056}, {"text": "merely about humanity's\nmetaphorical journey into the future.", "start": 779.0, "duration": 3.2}, {"text": "So one option that some\nof my AI colleagues like", "start": 782.92, "duration": 3.496}, {"text": "is to build superintelligence\nand keep it under human control,", "start": 786.44, "duration": 3.616}, {"text": "like an enslaved god,", "start": 790.08, "duration": 1.736}, {"text": "disconnected from the internet", "start": 791.84, "duration": 1.576}, {"text": "and used to create unimaginable\ntechnology and wealth", "start": 793.44, "duration": 3.256}, {"text": "for whoever controls it.", "start": 796.72, "duration": 1.24}, {"text": "But Lord Acton warned us", "start": 798.8, "duration": 1.456}, {"text": "that power corrupts,\nand absolute power corrupts absolutely,", "start": 800.28, "duration": 3.616}, {"text": "so you might worry that maybe\nwe humans just aren't smart enough,", "start": 803.92, "duration": 4.056}, {"text": "or wise enough rather,", "start": 808.0, "duration": 1.536}, {"text": "to handle this much power.", "start": 809.56, "duration": 1.24}, {"text": "Also, aside from any\nmoral qualms you might have", "start": 811.64, "duration": 2.536}, {"text": "about enslaving superior minds,", "start": 814.2, "duration": 2.296}, {"text": "you might worry that maybe\nthe superintelligence could outsmart us,", "start": 816.52, "duration": 3.976}, {"text": "break out and take over.", "start": 820.52, "duration": 2.24}, {"text": "But I also have colleagues\nwho are fine with AI taking over", "start": 823.56, "duration": 3.416}, {"text": "and even causing human extinction,", "start": 827.0, "duration": 2.296}, {"text": "as long as we feel the the AIs\nare our worthy descendants,", "start": 829.32, "duration": 3.576}, {"text": "like our children.", "start": 832.92, "duration": 1.736}, {"text": "But how would we know that the AIs\nhave adopted our best values", "start": 834.68, "duration": 5.616}, {"text": "and aren't just unconscious zombies\ntricking us into anthropomorphizing them?", "start": 840.32, "duration": 4.376}, {"text": "Also, shouldn't those people\nwho don't want human extinction", "start": 844.72, "duration": 2.856}, {"text": "have a say in the matter, too?", "start": 847.6, "duration": 1.44}, {"text": "Now, if you didn't like either\nof those two high-tech options,", "start": 850.2, "duration": 3.376}, {"text": "it's important to remember\nthat low-tech is suicide", "start": 853.6, "duration": 3.176}, {"text": "from a cosmic perspective,", "start": 856.8, "duration": 1.256}, {"text": "because if we don't go far\nbeyond today's technology,", "start": 858.08, "duration": 2.496}, {"text": "the question isn't whether humanity\nis going to go extinct,", "start": 860.6, "duration": 2.816}, {"text": "merely whether\nwe're going to get taken out", "start": 863.44, "duration": 2.016}, {"text": "by the next killer asteroid, supervolcano", "start": 865.48, "duration": 2.136}, {"text": "or some other problem\nthat better technology could have solved.", "start": 867.64, "duration": 3.096}, {"text": "So, how about having\nour cake and eating it ...", "start": 870.76, "duration": 3.576}, {"text": "with AGI that's not enslaved", "start": 874.36, "duration": 1.84}, {"text": "but treats us well because its values\nare aligned with ours?", "start": 877.12, "duration": 3.176}, {"text": "This is the gist of what Eliezer Yudkowsky\nhas called \"friendly AI,\"", "start": 880.32, "duration": 4.176}, {"text": "and if we can do this,\nit could be awesome.", "start": 884.52, "duration": 2.68}, {"text": "It could not only eliminate negative\nexperiences like disease, poverty,", "start": 887.84, "duration": 4.816}, {"text": "crime and other suffering,", "start": 892.68, "duration": 1.456}, {"text": "but it could also give us\nthe freedom to choose", "start": 894.16, "duration": 2.816}, {"text": "from a fantastic new diversity\nof positive experiences --", "start": 897.0, "duration": 4.056}, {"text": "basically making us\nthe masters of our own destiny.", "start": 901.08, "duration": 3.16}, {"text": "So in summary,", "start": 906.28, "duration": 1.376}, {"text": "our situation with technology\nis complicated,", "start": 907.68, "duration": 3.096}, {"text": "but the big picture is rather simple.", "start": 910.8, "duration": 2.416}, {"text": "Most AI researchers\nexpect AGI within decades,", "start": 913.24, "duration": 3.456}, {"text": "and if we just bumble\ninto this unprepared,", "start": 916.72, "duration": 3.136}, {"text": "it will probably be\nthe biggest mistake in human history --", "start": 919.88, "duration": 3.336}, {"text": "let's face it.", "start": 923.24, "duration": 1.416}, {"text": "It could enable brutal,\nglobal dictatorship", "start": 924.68, "duration": 2.576}, {"text": "with unprecedented inequality,\nsurveillance and suffering,", "start": 927.28, "duration": 3.536}, {"text": "and maybe even human extinction.", "start": 930.84, "duration": 1.976}, {"text": "But if we steer carefully,", "start": 932.84, "duration": 2.32}, {"text": "we could end up in a fantastic future\nwhere everybody's better off:", "start": 936.04, "duration": 3.896}, {"text": "the poor are richer, the rich are richer,", "start": 939.96, "duration": 2.376}, {"text": "everybody is healthy\nand free to live out their dreams.", "start": 942.36, "duration": 3.96}, {"text": "Now, hang on.", "start": 947.0, "duration": 1.536}, {"text": "Do you folks want the future\nthat's politically right or left?", "start": 948.56, "duration": 4.576}, {"text": "Do you want the pious society\nwith strict moral rules,", "start": 953.16, "duration": 2.856}, {"text": "or do you an hedonistic free-for-all,", "start": 956.04, "duration": 1.816}, {"text": "more like Burning Man 24/7?", "start": 957.88, "duration": 2.216}, {"text": "Do you want beautiful beaches,\nforests and lakes,", "start": 960.12, "duration": 2.416}, {"text": "or would you prefer to rearrange\nsome of those atoms with the computers,", "start": 962.56, "duration": 3.416}, {"text": "enabling virtual experiences?", "start": 966.0, "duration": 1.715}, {"text": "With friendly AI, we could simply\nbuild all of these societies", "start": 967.739, "duration": 3.157}, {"text": "and give people the freedom\nto choose which one they want to live in", "start": 970.92, "duration": 3.216}, {"text": "because we would no longer\nbe limited by our intelligence,", "start": 974.16, "duration": 3.096}, {"text": "merely by the laws of physics.", "start": 977.28, "duration": 1.456}, {"text": "So the resources and space\nfor this would be astronomical --", "start": 978.76, "duration": 4.616}, {"text": "literally.", "start": 983.4, "duration": 1.32}, {"text": "So here's our choice.", "start": 985.32, "duration": 1.2}, {"text": "We can either be complacent\nabout our future,", "start": 987.88, "duration": 2.32}, {"text": "taking as an article of blind faith", "start": 991.44, "duration": 2.656}, {"text": "that any new technology\nis guaranteed to be beneficial,", "start": 994.12, "duration": 4.016}, {"text": "and just repeat that to ourselves\nas a mantra over and over and over again", "start": 998.16, "duration": 4.136}, {"text": "as we drift like a rudderless ship\ntowards our own obsolescence.", "start": 1002.32, "duration": 3.68}, {"text": "Or we can be ambitious --", "start": 1006.92, "duration": 1.88}, {"text": "thinking hard about how\nto steer our technology", "start": 1009.84, "duration": 2.456}, {"text": "and where we want to go with it", "start": 1012.32, "duration": 1.936}, {"text": "to create the age of amazement.", "start": 1014.28, "duration": 1.76}, {"text": "We're all here to celebrate\nthe age of amazement,", "start": 1017.0, "duration": 2.856}, {"text": "and I feel that its essence should lie\nin becoming not overpowered", "start": 1019.88, "duration": 4.44}, {"text": "but empowered by our technology.", "start": 1025.24, "duration": 2.616}, {"text": "Thank you.", "start": 1027.88, "duration": 1.376}, {"text": "(Applause)", "start": 1029.28, "duration": 3.08}]